# -*- coding: utf-8 -*-
"""Copy of diabetes_breast_cancer_classification_commented.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pD5mHaITu6b0AlBpaXKqDTa7A7rvBnjn

# Diabetes and Breast Cancer Classification

## üìå Introduction

Steps:  
1. Load and explore the data.  
2. Preprocess (clean, split, scale).  
3. Train and compare models (KNN, SVM, Logistic Regression, Random Forest).  
4. Evaluate using metrics (accuracy, precision, recall, F1, ROC-AUC).  
5. Visualize performance with ROC curves.  
6. Apply to Breast Cancer dataset to show workflow generalization.
"""

# üì¶ Import essential libraries for handling data, plotting, and ML models
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_breast_cancer

# üîΩ Load the diabetes dataset directly from an online source and inspect the first rows
url = 'https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv'
df = pd.read_csv(url)
print('Shape:', df.shape)
print(df.info())
print(df.describe().T.head())
print('Missing values:\n', df.isnull().sum())

# üìä Correlation heatmap helps to see relationships between features and the outcome
plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# ‚úÇ Split the dataset into training and testing sets and scale features for fair model training
X = df.drop('Outcome', axis=1)
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
print('Train:', X_train.shape, 'Test:', X_test.shape)

# ‚öôÔ∏è Train multiple models, evaluate them, and collect metrics for comparison
def evaluate_model(name, model, X_tr, X_te, y_tr, y_te):
    model.fit(X_tr, y_tr)
    preds = model.predict(X_te)
    if hasattr(model,'predict_proba'):
        probs = model.predict_proba(X_te)[:,1]
    else:
        probs = model.decision_function(X_te)
    acc = accuracy_score(y_te, preds)
    prec = precision_score(y_te, preds)
    rec = recall_score(y_te, preds)
    f1 = f1_score(y_te, preds)
    roc = roc_auc_score(y_te, probs)
    print(f'\n{name} Metrics:\nAcc:{acc:.3f} Prec:{prec:.3f} Rec:{rec:.3f} F1:{f1:.3f} ROC-AUC:{roc:.3f}')
    print('Confusion Matrix:\n', confusion_matrix(y_te,preds))
    return (name, acc, prec, rec, f1, roc)

knn = KNeighborsClassifier(n_neighbors=5)
svm = SVC(kernel='linear', probability=True, random_state=42)
log_reg = LogisticRegression(max_iter=1000)
rf = RandomForestClassifier(random_state=42)
results = []
for name, model in [('KNN',knn),('SVM',svm),('LogReg',log_reg),('RF',rf)]:
    results.append(evaluate_model(name, model, X_train_scaled if name!='RF' else X_train,
                                  X_test_scaled if name!='RF' else X_test,
                                  y_train,y_test))
import pandas as pd
metrics_df = pd.DataFrame(results, columns=['Model','Accuracy','Precision','Recall','F1','ROC-AUC'])
metrics_df

# üìà Draw ROC curves for each model to compare their ability to distinguish classes
plt.figure(figsize=(8,6))
for name, model in [('KNN',knn),('SVM',svm),('LogReg',log_reg),('RF',rf)]:
    probs = model.predict_proba(X_test_scaled if name!='RF' else X_test)[:,1]
    fpr, tpr, _ = roc_curve(y_test, probs)
    plt.plot(fpr,tpr,label=f'{name}')
plt.plot([0,1],[0,1],'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves - Diabetes')
plt.legend()
plt.show()

# üß™ Apply the same workflow to the Breast Cancer dataset to test generalizability
bc = load_breast_cancer()
X_bc = pd.DataFrame(bc.data,columns=bc.feature_names)
y_bc = bc.target
Xtr_bc,Xte_bc,ytr_bc,yte_bc = train_test_split(X_bc,y_bc,test_size=0.2,random_state=42,stratify=y_bc)
sc_bc = StandardScaler()
Xtr_bc_s = sc_bc.fit_transform(Xtr_bc)
Xte_bc_s = sc_bc.transform(Xte_bc)
log_bc = LogisticRegression(max_iter=1000)
log_bc.fit(Xtr_bc_s,ytr_bc)
ypred_bc = log_bc.predict(Xte_bc_s)
print('Breast Cancer Accuracy:', accuracy_score(yte_bc,ypred_bc))